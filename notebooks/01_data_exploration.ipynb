{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30554520",
   "metadata": {},
   "source": [
    "# Machine Learning Course: Data Exploration\n",
    "\n",
    "## Notebook 1: Initial Data Exploration of the Metabric Dataset\n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Load and examine the structure of transcriptomics and clinical data\n",
    "2. Identify and handle missing values in genomics datasets\n",
    "3. Explore clinical variables and their distributions\n",
    "4. Understand sample types and patient characteristics\n",
    "5. Visualize key patterns in the data\n",
    "6. Assess data quality and identify potential issues\n",
    "\n",
    "### Dataset Overview\n",
    "The Metabric (Molecular Taxonomy of Breast Cancer International Consortium) dataset contains:\n",
    "- **Gene expression data**: ~24,000 genes across ~2,000 breast cancer samples\n",
    "- **Clinical data**: Patient demographics, tumor characteristics, and survival outcomes\n",
    "- **Sample metadata**: Information about sample collection and processing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b9c16",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7c1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 1: Import Required Libraries\n",
    "# \n",
    "# Your task: Import the necessary libraries for data analysis and visualization\n",
    "# \n",
    "# TODO: Import the following libraries with appropriate aliases:\n",
    "# 1. pandas (as pd) - for data manipulation\n",
    "# 2. numpy (as np) - for numerical operations  \n",
    "# 3. matplotlib.pyplot (as plt) - for plotting\n",
    "# 4. seaborn (as sns) - for statistical visualization\n",
    "# 5. os - for file system operations\n",
    "# 6. warnings - to suppress warning messages\n",
    "#\n",
    "# TODO: Import specific modules:\n",
    "# 7. From scipy.stats import: stats, chi2_contingency\n",
    "#\n",
    "# TODO: Configure the environment:\n",
    "# 8. Suppress warnings using warnings.filterwarnings('ignore')\n",
    "# 9. Set matplotlib plotting style to 'default'\n",
    "# 10. Set seaborn color palette to \"husl\"\n",
    "# 11. Set numpy random seed to 42 for reproducibility\n",
    "#\n",
    "# TODO: Print library versions to verify imports:\n",
    "# 12. Print versions of pandas, numpy, matplotlib, and seaborn\n",
    "# 13. Create the '../data' directory if it doesn't exist using os.makedirs()\n",
    "#\n",
    "# Expected output: Success messages with library versions and confirmation of data directory creation\n",
    "\n",
    "# Write your code below:\n",
    "# import ...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be00b6",
   "metadata": {},
   "source": [
    "## 2. Task 1: Data Loading\n",
    "\n",
    "Let's start by loading the Metabric dataset. We'll load both the gene expression data and clinical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1058ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 2: Set Up Data Loading Configuration\n",
    "#\n",
    "# Your task: Define the data file paths based on the actual files in the data folder\n",
    "#\n",
    "# TODO: Define variables for data organization:\n",
    "# 1. Create a variable DATA_PATH pointing to '../data/'\n",
    "# 2. Define file names for the actual datasets present:\n",
    "#    - CLINICAL_PATIENT_FILE = 'data_clinical_patient.txt'\n",
    "#    - CLINICAL_SAMPLE_FILE = 'data_clinical_sample.txt'  \n",
    "#    - EXPRESSION_FILE = 'data_mrna_illumina_microarray.txt'\n",
    "#\n",
    "# TODO: Create an informative display:\n",
    "# 3. Print a header \"=== METABRIC DATA FILES STATUS ===\"\n",
    "# 4. Show information about the data files:\n",
    "#    - All three data files are now present\n",
    "#    - Clinical files have comment headers (start with #)\n",
    "#    - Expression file is direct tab-separated format (no comments)\n",
    "#    - Expression file contains ~20,603 genes\n",
    "#\n",
    "# TODO: Check file availability:\n",
    "# 5. Create a list of the three file names\n",
    "# 6. Loop through each file and check if os.path.exists(os.path.join(DATA_PATH, file))\n",
    "# 7. Print ‚úì for found files and ‚ö†Ô∏è for missing files\n",
    "# 8. Display the expected file paths for any missing files\n",
    "# 9. Print a summary message about file availability\n",
    "#\n",
    "# TODO: Provide dataset information:\n",
    "# 10. Print information about expected data structure:\n",
    "#     - Clinical patient data: ~1,904 patients with clinical variables\n",
    "#     - Clinical sample data: Sample-level information\n",
    "#     - Expression data: ~20,603 genes √ó ~1,904 samples (Illumina microarray data)\n",
    "#\n",
    "# Expected output: File availability status and dataset structure information\n",
    "\n",
    "# Write your code below:\n",
    "# DATA_PATH = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5319900b",
   "metadata": {},
   "source": [
    "### 2.1 Load Gene Expression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf40860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 3: Load Gene Expression Data\n",
    "#\n",
    "# Your task: Load the Illumina microarray expression data (tab-separated format)\n",
    "#\n",
    "# TODO: Implement file loading with error handling:\n",
    "# 1. Use a try-except block to handle potential file loading errors\n",
    "# 2. Create the full file path using os.path.join(DATA_PATH, EXPRESSION_FILE)\n",
    "# 3. Check if the file exists using os.path.exists()\n",
    "#\n",
    "# TODO: Load the expression data correctly:\n",
    "# 4. The file is tab-separated with NO comment lines\n",
    "# 5. First column is Hugo_Symbol (gene names), second is Entrez_Gene_Id\n",
    "# 6. Use pd.read_csv(file_path, sep='\\t', index_col=0) to load with gene symbols as index\n",
    "# 7. This will make Hugo_Symbol the row index (gene names)\n",
    "# 8. You can drop the Entrez_Gene_Id column if desired: .drop('Entrez_Gene_Id', axis=1)\n",
    "#\n",
    "# TODO: Display data information:\n",
    "# 9. Print the shape of the loaded data\n",
    "# 10. Print number of genes (rows) and samples (columns) with comma formatting\n",
    "# 11. Print the data type (should be float64 for expression values)\n",
    "# 12. Show first few gene names (index) and sample names (columns)\n",
    "# 13. Display a small preview (first 5 genes √ó 5 samples)\n",
    "#\n",
    "# TODO: Validate the data structure:\n",
    "# 14. Check that sample names follow MB-XXXX format\n",
    "# 15. Verify expression values are in reasonable range (log2 or similar scale)\n",
    "# 16. Check for any obvious data quality issues\n",
    "#\n",
    "# TODO: Handle loading errors:\n",
    "# 17. If file loading fails, print informative error message\n",
    "# 18. You can still create dummy data if needed for practice\n",
    "# 19. But the real data should load successfully now\n",
    "#\n",
    "# Expected output: Successful loading of ~20,603 genes √ó ~1,904 samples expression matrix\n",
    "\n",
    "# Write your code below:\n",
    "# try:\n",
    "#     expression_file_path = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7918aa",
   "metadata": {},
   "source": [
    "### 2.2 Load Clinical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883098a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 4: Load Clinical Patient Data\n",
    "#\n",
    "# Your task: Load the actual clinical patient data (tab-separated format)\n",
    "#\n",
    "# TODO: Implement robust clinical data loading:\n",
    "# 1. Create a try-except structure for error handling\n",
    "# 2. Build the file path using os.path.join(DATA_PATH, CLINICAL_PATIENT_FILE)\n",
    "# 3. Note: The file is tab-separated with comment lines starting with #\n",
    "#\n",
    "# TODO: Load the tab-separated file:\n",
    "# 4. Use pd.read_csv(file_path, sep='\\t', comment='#') to skip header lines\n",
    "# 5. If that fails, try without comment parameter\n",
    "# 6. If still fails, try with encoding='latin-1'\n",
    "# 7. Print which loading method worked\n",
    "#\n",
    "# TODO: Display clinical data information:\n",
    "# 8. Print the shape (rows, columns) with comma formatting\n",
    "# 9. Print number of patients and clinical variables\n",
    "# 10. Show the column names (there should be many clinical variables)\n",
    "# 11. Display the first few rows to understand the data structure\n",
    "#\n",
    "# TODO: Explore the actual column names present:\n",
    "# 12. The file contains columns like: PATIENT_ID, AGE_AT_DIAGNOSIS, OS_MONTHS, etc.\n",
    "# 13. Print a sample of column names to see what clinical variables are available\n",
    "# 14. Look for key variables: ER_IHC, HER2_SNP6, CLAUDIN_SUBTYPE, etc.\n",
    "#\n",
    "# TODO: Handle any loading errors:\n",
    "# 15. If file loading fails, print the error message\n",
    "# 16. Provide guidance on checking file format or permissions\n",
    "#\n",
    "# Expected output: Clinical data loading status and structure information\n",
    "\n",
    "# Write your code below:\n",
    "# try:\n",
    "#     clinical_file_path = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f2f68",
   "metadata": {},
   "source": [
    "### 2.3 Load Sample Metadata (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a43020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 5: Load Clinical Sample Data\n",
    "#\n",
    "# Your task: Load the sample-level clinical data (tab-separated format)\n",
    "#\n",
    "# TODO: Implement sample data loading:\n",
    "# 1. Use try-except to handle potential loading issues\n",
    "# 2. Create file path using os.path.join(DATA_PATH, CLINICAL_SAMPLE_FILE)\n",
    "# 3. This file contains sample-level information (may have multiple samples per patient)\n",
    "#\n",
    "# TODO: Load the tab-separated sample file:\n",
    "# 4. Use pd.read_csv(file_path, sep='\\t', comment='#') to skip header lines\n",
    "# 5. If that fails, try without comment parameter\n",
    "# 6. Print which format worked\n",
    "# 7. Display shape and basic information if successful\n",
    "#\n",
    "# TODO: Explore sample data structure:\n",
    "# 8. Print column names to see what sample-level variables are available\n",
    "# 9. Look for key columns: SAMPLE_ID, PATIENT_ID, TUMOR_SIZE, TUMOR_STAGE, etc.\n",
    "# 10. Check if there are multiple samples per patient\n",
    "# 11. Show first few rows to understand data structure\n",
    "#\n",
    "# TODO: Compare with patient data:\n",
    "# 12. Compare PATIENT_ID values between clinical_data and sample_data\n",
    "# 13. Check if all patients have corresponding sample records\n",
    "# 14. Note any differences in the number of records\n",
    "#\n",
    "# TODO: Handle errors gracefully:\n",
    "# 15. If file loading fails, print error message and continue\n",
    "# 16. Set sample_data = None if loading fails\n",
    "#\n",
    "# Expected output: Sample data information and comparison with patient data\n",
    "\n",
    "# Write your code below:\n",
    "# try:\n",
    "#     sample_file_path = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660fb612",
   "metadata": {},
   "source": [
    "### 2.4 Data Loading Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72952a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 6: Create Data Loading Summary\n",
    "#\n",
    "# Your task: Generate a comprehensive summary of loaded datasets\n",
    "#\n",
    "# TODO: Create a formatted summary display:\n",
    "# 1. Print a header with \"=\" characters: \"DATA LOADING SUMMARY\"  \n",
    "# 2. Add separator line with 60 \"=\" characters\n",
    "#\n",
    "# TODO: Display dataset information:\n",
    "# 3. Print expression data dimensions using :, formatting for thousands\n",
    "# 4. Print clinical data dimensions with thousands separators\n",
    "# 5. Handle the case where sample_data might be None\n",
    "# 6. Display data types for each dataset\n",
    "#\n",
    "# TODO: Calculate and display memory usage:\n",
    "# 7. Calculate memory usage for expression_data using .memory_usage(deep=True).sum()\n",
    "# 8. Calculate memory usage for clinical_data the same way  \n",
    "# 9. Convert bytes to MB by dividing by 1024**2\n",
    "# 10. Display individual and total memory usage with 2 decimal places\n",
    "#\n",
    "# TODO: Add helpful context:\n",
    "# 11. Print information about data types (DataFrame, etc.)\n",
    "# 12. Provide guidance on what the numbers mean\n",
    "# 13. Mention whether real or dummy data is being used\n",
    "#\n",
    "# Expected output: Professional summary with dataset dimensions, types, and memory usage\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"DATA LOADING SUMMARY\")\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df87d0",
   "metadata": {},
   "source": [
    "### üîÑ **Quick Data Download Guide**\n",
    "\n",
    "If you haven't downloaded the data yet, follow these steps:\n",
    "\n",
    "1. **Create the data directory** (done automatically above)\n",
    "\n",
    "2. **Download each file** by clicking these links and saving to `../data/`:\n",
    "   - [Clinical Patient Data](https://drive.google.com/file/d/15AXx2ZKiQ8MhK8EgK6xnE0XbW_PAxY0j/view?usp=sharing) ‚Üí Save as `clinical_patient_data.csv`\n",
    "   - [Clinical Sample Data](https://drive.google.com/file/d/1q4I2v-12jUrwJ3Jf8CICi235ZvsODDW7/view?usp=sharing) ‚Üí Save as `clinical_sample_data.csv`\n",
    "   - [Expression Data](https://drive.google.com/file/d/1q4I2v-12jUrwJ3Jf8CICi235ZvsODDW7/view?usp=sharing) ‚Üí Save as `expression_data.csv`\n",
    "\n",
    "3. **Re-run the data loading cells** above to load the real data\n",
    "\n",
    "**Note**: The notebook will work with dummy data if files are not available, but real data is recommended for meaningful analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f38da",
   "metadata": {},
   "source": [
    "## 3. Task 2: Data Exploration\n",
    "\n",
    "Now let's explore the loaded data to understand its structure, quality, and characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939e4fb4",
   "metadata": {},
   "source": [
    "### 3.1 Expression Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ca9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 7: Explore Expression Data Structure\n",
    "#\n",
    "# Your task: Examine the basic structure and characteristics of gene expression data\n",
    "#\n",
    "# TODO: Display basic dataset information:\n",
    "# 1. Print \"EXPRESSION DATA EXPLORATION\" header with \"=\" separators\n",
    "# 2. Print the shape of expression_data\n",
    "# 3. Print the data type of the first column (use .dtypes.iloc[0])\n",
    "# 4. Print the index name (genes) - handle case where it might be None\n",
    "# 5. Print the columns name (samples) - handle case where it might be None\n",
    "#\n",
    "# TODO: Show sample of data structure:\n",
    "# 6. Print \"First few genes:\" and display first 10 gene names as a list\n",
    "# 7. Print \"First few samples:\" and display first 10 sample names as a list  \n",
    "# 8. Print \"Expression data preview:\" and display first 5 rows √ó 5 columns\n",
    "# 9. Use display() function to show the DataFrame preview nicely\n",
    "#\n",
    "# TODO: Provide context:\n",
    "# 10. Add explanatory text about what genes and samples represent\n",
    "# 11. Explain what the expression values likely represent (Z-scores, log2, etc.)\n",
    "#\n",
    "# Expected output: Structured overview of expression data dimensions, types, and preview\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"EXPRESSION DATA EXPLORATION\")\n",
    "# print(\"=\"*50)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 8: Calculate Expression Data Statistics\n",
    "#\n",
    "# Your task: Compute and display statistical summaries of expression values\n",
    "#\n",
    "# TODO: Calculate overall statistics:\n",
    "# 1. Print \"Statistical Summary of Expression Data:\" with separator line\n",
    "# 2. Calculate and print the overall mean of all expression values\n",
    "# 3. Calculate and print the overall standard deviation\n",
    "# 4. Calculate and print minimum and maximum values\n",
    "# 5. Calculate and print the median using np.median()\n",
    "# 6. Format all statistics to 3 decimal places\n",
    "#\n",
    "# TODO: Perform data quality checks:\n",
    "# 7. Count infinite values using np.isinf() and .sum()\n",
    "# 8. Count extreme values where |x| > 10 using np.abs() and boolean indexing\n",
    "# 9. Calculate percentage of extreme values relative to total data size\n",
    "# 10. Print these quality metrics with appropriate labels\n",
    "#\n",
    "# TODO: Interpret the results:\n",
    "# 11. Add comments about what these statistics tell us about data quality\n",
    "# 12. Explain what we'd expect for normalized expression data (Z-scores)\n",
    "# 13. Flag any concerning patterns (too many extreme values, etc.)\n",
    "#\n",
    "# Expected output: Comprehensive statistical summary with quality assessments\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"Statistical Summary of Expression Data:\")\n",
    "# print(\"=\"*50)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10731df",
   "metadata": {},
   "source": [
    "### 3.2 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ce7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 9: Analyze Missing Values Pattern\n",
    "#\n",
    "# Your task: Systematically analyze missing values in both expression and clinical data\n",
    "#\n",
    "# TODO: Set up missing values analysis:\n",
    "# 1. Print \"MISSING VALUES ANALYSIS\" header with \"=\" separators\n",
    "# 2. Start with expression data analysis\n",
    "#\n",
    "# TODO: Analyze expression data missing values:\n",
    "# 3. Use .isnull().sum() to count missing values per gene\n",
    "# 4. Find genes with missing values using boolean indexing (where count > 0)\n",
    "# 5. Calculate total missing values and percentage of total dataset size\n",
    "# 6. Print summary: total missing, genes affected, percentage\n",
    "# 7. If genes have missing values, show top 10 genes with most missing values\n",
    "# 8. If no missing values, print a success message with checkmark\n",
    "#\n",
    "# TODO: Analyze clinical data missing values:\n",
    "# 9. Print separator line and \"Clinical Data Missing Values:\"\n",
    "# 10. Calculate missing values per clinical variable using same approach\n",
    "# 11. Find variables with missing values\n",
    "# 12. Calculate total missing values and percentage\n",
    "# 13. If variables have missing values, create a summary DataFrame with:\n",
    "#    - Missing_Count: number of missing values per variable\n",
    "#    - Missing_Percentage: percentage of patients missing this variable\n",
    "# 14. Sort by missing count (descending) and display using display()\n",
    "# 15. If no missing values, print success message\n",
    "#\n",
    "# Expected output: Comprehensive missing values report for both datasets\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"MISSING VALUES ANALYSIS\")\n",
    "# print(\"=\"*50)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 10: Visualize Missing Values Pattern\n",
    "#\n",
    "# Your task: Create visualizations to understand missing data patterns\n",
    "#\n",
    "# TODO: Create conditional visualization:\n",
    "# 1. Check if clinical_data has any missing values using .isnull().sum().sum() > 0\n",
    "# 2. If there are missing values, create a figure with 2 subplots using plt.subplots(1, 2, figsize=(15, 6))\n",
    "#\n",
    "# TODO: Create missing values heatmap (left subplot):\n",
    "# 3. Use sns.heatmap() to plot clinical_data.isnull()\n",
    "# 4. Set parameters: cbar=True, cmap='viridis'\n",
    "# 5. Set title: 'Missing Values Pattern in Clinical Data'\n",
    "# 6. Set xlabel: 'Variables', ylabel: 'Patients'\n",
    "#\n",
    "# TODO: Create missing values bar plot (right subplot):\n",
    "# 7. Get missing counts for variables with missing values only\n",
    "# 8. Create bar plot using .plot(kind='bar')\n",
    "# 9. Set title: 'Missing Values Count by Variable'\n",
    "# 10. Set xlabel: 'Variables', ylabel: 'Missing Count'\n",
    "# 11. Rotate x-axis labels by 45 degrees using tick_params(axis='x', rotation=45)\n",
    "#\n",
    "# TODO: Finalize the plot:\n",
    "# 12. Use plt.tight_layout() to prevent overlap\n",
    "# 13. Use plt.show() to display\n",
    "# 14. If no missing values, print \"No missing values to visualize.\"\n",
    "#\n",
    "# Expected output: Heatmap and bar chart showing missing value patterns (or message if none)\n",
    "\n",
    "# Write your code below:\n",
    "# if clinical_data.isnull().sum().sum() > 0:\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a4bfa",
   "metadata": {},
   "source": [
    "### 3.3 Clinical Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01971ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 11: Explore Clinical Data Structure\n",
    "#\n",
    "# Your task: Examine the structure and content of clinical data\n",
    "#\n",
    "# TODO: Display basic clinical data information:\n",
    "# 1. Print \"CLINICAL DATA EXPLORATION\" header with \"=\" separators\n",
    "# 2. Print number of patients using len(clinical_data) with comma formatting\n",
    "# 3. Print number of variables using len(clinical_data.columns) with comma formatting\n",
    "#\n",
    "# TODO: Show column information systematically:\n",
    "# 4. Print \"Column names and data types:\"\n",
    "# 5. Loop through clinical_data.columns and clinical_data.dtypes using zip()\n",
    "# 6. Print each column with index number, name (left-aligned in 30 characters), and data type\n",
    "# 7. Use string formatting: f\"{i+1:2d}. {col:<30} {str(dtype):<10}\"\n",
    "#\n",
    "# TODO: Display data preview:\n",
    "# 8. Print \"First few rows:\"\n",
    "# 9. Use display(clinical_data.head()) to show first 5 rows in nice format\n",
    "#\n",
    "# Expected output: Systematic overview of clinical data structure, columns, and preview\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"CLINICAL DATA EXPLORATION\")\n",
    "# print(\"=\"*50)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 12: Categorize and Summarize Clinical Variables\n",
    "#\n",
    "# Your task: Identify different types of clinical variables and provide summaries\n",
    "#\n",
    "# TODO: Categorize variables by data type:\n",
    "# 1. Use clinical_data.select_dtypes(include=[np.number]) to get numerical variables\n",
    "# 2. Use clinical_data.select_dtypes(include=['object', 'category']) to get categorical variables\n",
    "# 3. Convert to lists using .columns.tolist()\n",
    "#\n",
    "# TODO: Display variable categories:\n",
    "# 4. Print f\"Numerical variables ({len(numerical_vars)}):\" \n",
    "# 5. Loop through numerical_vars and print each with bullet point: f\"  - {var}\"\n",
    "# 6. Print f\"Categorical variables ({len(categorical_vars)}):\"\n",
    "# 7. Loop through categorical_vars and print each with unique count: f\"  - {var} ({unique_count} unique values)\"\n",
    "# 8. Get unique count using clinical_data[var].nunique()\n",
    "#\n",
    "# TODO: Show numerical variables summary:\n",
    "# 9. Check if len(numerical_vars) > 0\n",
    "# 10. If yes, print \"Numerical Variables Summary:\"\n",
    "# 11. Use display(clinical_data[numerical_vars].describe()) to show statistics\n",
    "#\n",
    "# Expected output: Categorized variable lists and statistical summary for numerical variables\n",
    "\n",
    "# Write your code below:\n",
    "# numerical_vars = clinical_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# categorical_vars = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca5506",
   "metadata": {},
   "source": [
    "## üí° Coding Hints and Templates\n",
    "\n",
    "Need help getting started? Here are some code templates and hints for the actual Metabric data:\n",
    "\n",
    "### üìã **Template: Clinical Data Loading (with comment headers)**\n",
    "```python\n",
    "# Clinical files have comment lines starting with #\n",
    "try:\n",
    "    file_path = os.path.join(DATA_PATH, 'data_clinical_patient.txt')\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path, sep='\\t', comment='#')\n",
    "        print(f\"‚úì Loaded clinical data: {data.shape}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "```\n",
    "\n",
    "### üìã **Template: Expression Data Loading (direct format)**\n",
    "```python\n",
    "# Expression file is direct tab-separated, no comments\n",
    "try:\n",
    "    file_path = os.path.join(DATA_PATH, 'data_mrna_illumina_microarray.txt')\n",
    "    if os.path.exists(file_path):\n",
    "        # Use first column (Hugo_Symbol) as index\n",
    "        data = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "        # Optional: drop Entrez_Gene_Id column\n",
    "        if 'Entrez_Gene_Id' in data.columns:\n",
    "            data = data.drop('Entrez_Gene_Id', axis=1)\n",
    "        print(f\"‚úì Loaded expression data: {data.shape}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "```\n",
    "\n",
    "### üìä **Template: Missing Values Analysis**\n",
    "```python\n",
    "# Missing values template\n",
    "missing_data = dataset.isnull().sum()\n",
    "missing_vars = missing_data[missing_data > 0]\n",
    "total_missing = dataset.isnull().sum().sum()\n",
    "missing_pct = (total_missing / dataset.size) * 100\n",
    "print(f\"Missing values: {total_missing:,} ({missing_pct:.2f}%)\")\n",
    "```\n",
    "\n",
    "### üìà **Template: Basic Statistics**\n",
    "```python\n",
    "# Statistics template\n",
    "print(f\"Mean: {data.mean():.3f}\")\n",
    "print(f\"Std: {data.std():.3f}\")\n",
    "print(f\"Min: {data.min():.3f}\")\n",
    "print(f\"Max: {data.max():.3f}\")\n",
    "```\n",
    "\n",
    "### üé® **Template: Data Visualization**\n",
    "```python\n",
    "# Visualization template\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Plot 1\n",
    "data.hist(ax=axes[0])\n",
    "axes[0].set_title('Distribution')\n",
    "# Plot 2  \n",
    "data.plot(kind='box', ax=axes[1])\n",
    "axes[1].set_title('Box Plot')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### üîç **Key Metabric Data Info**\n",
    "- **Sample IDs**: Follow MB-XXXX format (e.g., MB-0362, MB-0346)\n",
    "- **Clinical Variables**: ER_IHC, HER2_SNP6, CLAUDIN_SUBTYPE, AGE_AT_DIAGNOSIS, OS_MONTHS, etc.\n",
    "- **Expression Values**: Log2-transformed Illumina microarray data\n",
    "- **Gene Names**: HGNC symbols (Hugo_Symbol column)\n",
    "- **File Formats**: Clinical = tab + comments, Expression = tab only\n",
    "\n",
    "### üîç **Common Methods to Remember**\n",
    "- `df.shape` - Get dimensions\n",
    "- `df.dtypes` - Get data types\n",
    "- `df.isnull().sum()` - Count missing values\n",
    "- `df.describe()` - Statistical summary\n",
    "- `df.head()` - Show first few rows\n",
    "- `df.nunique()` - Count unique values per column\n",
    "- `len(df)` - Number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdad13a",
   "metadata": {},
   "source": [
    "## üéØ Learning Assessment\n",
    "\n",
    "### ‚úÖ **Self-Check Questions**\n",
    "\n",
    "After completing the activities, you should be able to answer:\n",
    "\n",
    "1. **Data Loading & Structure**\n",
    "   - How many genes and samples are in the expression dataset? (~20,603 genes √ó ~1,904 samples)\n",
    "   - What data types are used for clinical variables?\n",
    "   - How do you handle files with comment headers vs. direct data format?\n",
    "   - What's the difference between Hugo_Symbol and Entrez_Gene_Id?\n",
    "\n",
    "2. **Missing Values**\n",
    "   - What percentage of values are missing in each dataset?\n",
    "   - Which clinical variables have the most missing data?\n",
    "   - Are there any missing values in the expression data?\n",
    "   - How might missing values affect your downstream analysis?\n",
    "\n",
    "3. **Data Quality**\n",
    "   - What is the range and distribution of expression values (should be log2-transformed)?\n",
    "   - Do any samples appear to be outliers based on their expression profiles?\n",
    "   - Are there genes with very low variance that might not be informative?\n",
    "   - How well do sample IDs match between clinical and expression data?\n",
    "\n",
    "4. **Clinical Characteristics**\n",
    "   - What are the key biomarker variables (ER_IHC, HER2_SNP6)?\n",
    "   - How are patients distributed across different molecular subtypes (CLAUDIN_SUBTYPE)?\n",
    "   - What is the age range and survival time distribution?\n",
    "   - What percentage of patients are ER+, HER2+, etc.?\n",
    "\n",
    "5. **Expression Data Characteristics**\n",
    "   - What genes show the highest variance across samples?\n",
    "   - How correlated are samples with each other?\n",
    "   - Do expression values follow expected distributions for microarray data?\n",
    "\n",
    "### üèÜ **Success Criteria**\n",
    "\n",
    "You have successfully completed this notebook if you can:\n",
    "- ‚úÖ Load all three datasets without errors\n",
    "- ‚úÖ Handle both comment-header and direct tab-separated formats\n",
    "- ‚úÖ Calculate basic statistics for both expression and clinical data\n",
    "- ‚úÖ Identify and quantify missing values in each dataset\n",
    "- ‚úÖ Categorize clinical variables into numerical vs categorical\n",
    "- ‚úÖ Create meaningful visualizations of data distributions\n",
    "- ‚úÖ Interpret the results and identify potential data quality issues\n",
    "- ‚úÖ Match samples between expression and clinical datasets\n",
    "\n",
    "### üöÄ **Extension Challenges** (Optional)\n",
    "\n",
    "For advanced students:\n",
    "1. **Cross-Dataset Analysis**:\n",
    "   - Compare expression variance across different ER status groups\n",
    "   - Analyze correlation between age and molecular subtypes\n",
    "   - Identify genes that might be associated with survival time\n",
    "\n",
    "2. **Advanced Visualizations**:\n",
    "   - Create correlation matrices between clinical variables\n",
    "   - Plot expression distributions by molecular subtype\n",
    "   - Generate sample-sample correlation heatmaps\n",
    "\n",
    "3. **Quality Control**:\n",
    "   - Identify potential batch effects in expression data\n",
    "   - Find outlier samples based on multiple criteria\n",
    "   - Assess data completeness across different patient groups\n",
    "\n",
    "4. **Statistical Analysis**:\n",
    "   - Perform t-tests comparing ER+ vs ER- expression profiles\n",
    "   - Calculate survival statistics by molecular subtype\n",
    "   - Test for associations between clinical variables\n",
    "\n",
    "5. **Data Integration**:\n",
    "   - Create a master dataset combining clinical and expression data\n",
    "   - Handle cases where sample IDs don't perfectly match\n",
    "   - Prepare data for machine learning modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9aab1d",
   "metadata": {},
   "source": [
    "### 3.4 Sample Types and Patient Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa17b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 13: Analyze Sample Types and Patient Characteristics\n",
    "#\n",
    "# Your task: Explore categorical variables and patient characteristics from the actual data\n",
    "#\n",
    "# TODO: Set up the analysis:\n",
    "# 1. Print \"SAMPLE TYPES AND PATIENT CHARACTERISTICS\" with \"=\" separators\n",
    "# 2. Remember the actual columns include: ER_IHC, HER2_SNP6, CLAUDIN_SUBTYPE, etc.\n",
    "#\n",
    "# TODO: Analyze categorical variables from the actual data:\n",
    "# 3. Select first 5 categorical variables to avoid overwhelming output\n",
    "# 4. For each categorical variable:\n",
    "#    - Print the variable name\n",
    "#    - Use .value_counts(dropna=False) to count occurrences including missing\n",
    "#    - Print the value counts\n",
    "# 5. Calculate and display percentages:\n",
    "#    - Use .value_counts(normalize=True, dropna=False) * 100\n",
    "#    - Loop through and print each value with percentage formatted to 1 decimal\n",
    "#\n",
    "# TODO: Focus on key clinical variables (if present):\n",
    "# 6. Look specifically for these important variables:\n",
    "#    - ER_IHC (Estrogen Receptor status)\n",
    "#    - HER2_SNP6 (HER2 status)  \n",
    "#    - CLAUDIN_SUBTYPE (molecular subtype)\n",
    "#    - INFERRED_MENOPAUSAL_STATE\n",
    "#    - VITAL_STATUS\n",
    "# 7. These tell us about patient characteristics and cancer types\n",
    "#\n",
    "# TODO: Interpret the results:\n",
    "# 8. Comment on what the distributions tell us about the patient cohort\n",
    "# 9. Note any imbalanced categories that might affect analysis\n",
    "#\n",
    "# Expected output: Distribution analysis of key categorical clinical variables\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"SAMPLE TYPES AND PATIENT CHARACTERISTICS\")\n",
    "# print(\"=\"*50)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd675ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 14: Create Clinical Characteristics Visualizations\n",
    "#\n",
    "# Your task: Create comprehensive visualizations of clinical data distributions\n",
    "#\n",
    "# TODO: Set up the visualization framework:\n",
    "# 1. Create a figure with subplots: plt.subplots(2, 3, figsize=(18, 12))\n",
    "# 2. Use axes.ravel() to flatten the axes array for easy indexing\n",
    "# 3. Initialize plot_idx = 0 to track which subplot you're using\n",
    "#\n",
    "# TODO: Create pie charts for categorical variables:\n",
    "# 4. Select categorical variables with ‚â§ 10 unique values (to fit in pie charts)\n",
    "# 5. For the first 4 suitable categorical variables:\n",
    "#    - Get value counts using .value_counts()\n",
    "#    - Create pie chart with axes[plot_idx].pie()\n",
    "#    - Set parameters: labels=value_counts.index, autopct='%1.1f%%', startangle=90\n",
    "#    - Set title: f'Distribution of {var}'\n",
    "#    - Increment plot_idx\n",
    "#\n",
    "# TODO: Create histograms for numerical variables:\n",
    "# 6. Select the first 2 numerical variables from your numerical_vars list\n",
    "# 7. For each numerical variable:\n",
    "#    - Create histogram using .hist(bins=30, ax=axes[plot_idx], alpha=0.7)\n",
    "#    - Set title, xlabel, and ylabel appropriately\n",
    "#    - Increment plot_idx\n",
    "#\n",
    "# TODO: Finalize the visualization:\n",
    "# 8. Hide any unused subplots using a loop and axes[i].set_visible(False)\n",
    "# 9. Use plt.tight_layout() to prevent overlapping\n",
    "# 10. Display with plt.show()\n",
    "#\n",
    "# Expected output: Professional multi-panel visualization showing distributions of key variables\n",
    "\n",
    "# Write your code below:\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "# axes = axes.ravel()\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f476a4e",
   "metadata": {},
   "source": [
    "### 3.5 Expression Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 15: Analyze Expression Data Distribution (if available)\n",
    "#\n",
    "# Your task: Create comprehensive analysis of gene expression distributions\n",
    "# Note: This activity only applies if expression data was successfully loaded\n",
    "#\n",
    "# TODO: Check if expression data is available:\n",
    "# 1. Use a conditional: if 'expression_data' in locals() and expression_data is not None:\n",
    "# 2. Print \"EXPRESSION DATA DISTRIBUTION ANALYSIS\" header with separators\n",
    "# 3. If no expression data, print message about needing to download the data file\n",
    "#\n",
    "# TODO: Prepare data for visualization:\n",
    "# 4. Sample a subset of genes to avoid overcrowding: min(100, expression_data.shape[0])\n",
    "# 5. Use np.random.choice() to randomly select genes for visualization\n",
    "# 6. Create sample_expression = expression_data.loc[sample_genes]\n",
    "#\n",
    "# TODO: Create a 2x2 subplot framework:\n",
    "# 7. Use plt.subplots(2, 2, figsize=(15, 10))\n",
    "#\n",
    "# TODO: Plot 1 - Overall expression distribution:\n",
    "# 8. Flatten all expression values: expression_data.values.flatten()\n",
    "# 9. Create histogram with bins=50, alpha=0.7, density=True\n",
    "# 10. Add title, labels, and a vertical line at mean (axvline at 0 for Z-scores)\n",
    "# 11. Add legend\n",
    "#\n",
    "# TODO: Plot 2 - Sample-wise distribution (boxplot):\n",
    "# 12. Select first 20 samples: expression_data.iloc[:, :20]\n",
    "# 13. Create boxplot for first 10 samples with appropriate labels\n",
    "# 14. Rotate x-axis labels by 45 degrees\n",
    "#\n",
    "# TODO: Plot 3 - Gene variance distribution:\n",
    "# 15. Calculate gene variances: expression_data.var(axis=1)\n",
    "# 16. Create histogram of variances\n",
    "# 17. Add vertical line at median variance\n",
    "#\n",
    "# TODO: Plot 4 - Sample means distribution:\n",
    "# 18. Calculate sample means: expression_data.mean(axis=0)\n",
    "# 19. Create histogram of sample means\n",
    "# 20. Use plt.tight_layout() and plt.show()\n",
    "#\n",
    "# TODO: Print summary statistics:\n",
    "# 21. Calculate and print overall statistics\n",
    "# 22. Count low and high variance genes\n",
    "# 23. Interpret what these distributions tell us about data quality\n",
    "#\n",
    "# Expected output: Multi-panel visualization of expression data characteristics (if data available)\n",
    "\n",
    "# Write your code below:\n",
    "# if 'expression_data' in locals() and expression_data is not None:\n",
    "#     print(\"EXPRESSION DATA DISTRIBUTION ANALYSIS\")\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f215211a",
   "metadata": {},
   "source": [
    "### 3.6 Sample-Sample Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d813bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 16: Sample-Sample Correlation Analysis (if expression data available)\n",
    "#\n",
    "# Your task: Analyze correlations between samples to assess data quality\n",
    "# Note: This requires expression data to be loaded\n",
    "#\n",
    "# TODO: Check for expression data availability:\n",
    "# 1. Use conditional: if 'expression_data' in locals() and expression_data is not None:\n",
    "# 2. Print \"SAMPLE-SAMPLE CORRELATION ANALYSIS\" header\n",
    "# 3. If no expression data, print guidance about downloading the file\n",
    "#\n",
    "# TODO: Prepare correlation analysis:\n",
    "# 4. For computational efficiency, limit to subset of samples: min(50, expression_data.shape[1])\n",
    "# 5. Select sample subset: expression_data.iloc[:, :n_samples_to_correlate]\n",
    "# 6. Print message about how many samples will be analyzed\n",
    "#\n",
    "# TODO: Calculate correlation matrix:\n",
    "# 7. Use sample_subset.corr() to calculate pairwise correlations\n",
    "# 8. This tells us how similar expression profiles are between samples\n",
    "#\n",
    "# TODO: Create correlation heatmap:\n",
    "# 9. Create figure with plt.figure(figsize=(12, 10))\n",
    "# 10. Create upper triangle mask: np.triu(np.ones_like(sample_corr, dtype=bool))\n",
    "# 11. Use sns.heatmap() with parameters:\n",
    "#     - mask=mask, cmap='coolwarm', center=0\n",
    "#     - square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}\n",
    "# 12. Set appropriate title and use plt.tight_layout(), plt.show()\n",
    "#\n",
    "# TODO: Calculate correlation statistics:\n",
    "# 13. Extract upper triangle: sample_corr.where(mask_condition)\n",
    "# 14. Stack to get 1D array of correlations\n",
    "# 15. Calculate and print: mean, std, min, max, median correlations\n",
    "#\n",
    "# TODO: Identify highly correlated samples:\n",
    "# 16. Set threshold (e.g., 0.95) for high correlation\n",
    "# 17. Find sample pairs with correlation above threshold\n",
    "# 18. Print count and top 5 most correlated pairs if any exist\n",
    "#\n",
    "# TODO: Interpret results:\n",
    "# 19. High correlations might indicate duplicates or very similar samples\n",
    "# 20. Very low correlations might indicate quality issues\n",
    "#\n",
    "# Expected output: Correlation heatmap and statistics (if expression data available)\n",
    "\n",
    "# Write your code below:\n",
    "# if 'expression_data' in locals() and expression_data is not None:\n",
    "#     print(\"SAMPLE-SAMPLE CORRELATION ANALYSIS\")\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da1040",
   "metadata": {},
   "source": [
    "### 3.7 Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ecdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 17: Comprehensive Data Quality Assessment\n",
    "#\n",
    "# Your task: Perform systematic quality checks on both expression and clinical data\n",
    "#\n",
    "# TODO: Set up quality assessment framework:\n",
    "# 1. Print \"DATA QUALITY ASSESSMENT\" header with separators\n",
    "# 2. Create separate sections for expression and clinical data\n",
    "#\n",
    "# TODO: Expression data quality checks (if available):\n",
    "# 3. Check if expression data exists: if 'expression_data' in locals():\n",
    "# 4. Print \"Expression Data Quality:\" with separator line\n",
    "# 5. Check for constant genes (genes with no variation): (expression_data.std(axis=1) == 0).sum()\n",
    "# 6. Check for low variance genes: (expression_data.var(axis=1) < 0.01).sum()\n",
    "# 7. Identify outlier samples using 3-sigma rule:\n",
    "#    - Calculate sample means and standard deviations\n",
    "#    - Find samples where |mean - overall_mean| > 3 * overall_std\n",
    "#    - Do the same for sample standard deviations\n",
    "# 8. Print counts of problematic genes and samples\n",
    "#\n",
    "# TODO: Clinical data quality checks:\n",
    "# 9. Print \"Clinical Data Quality:\" section\n",
    "# 10. Check for duplicate patient records:\n",
    "#     - If 'PATIENT_ID' in columns, use .duplicated() on that column\n",
    "#     - Otherwise check for completely duplicate rows\n",
    "# 11. Print duplicate count\n",
    "#\n",
    "# TODO: Check for impossible/invalid values:\n",
    "# 12. Create quality_issues list to collect problems\n",
    "# 13. For each numerical variable in clinical data:\n",
    "#     - Age variables: check for values < 0 or > 120\n",
    "#     - Size/measurement variables: check for negative values\n",
    "#     - Time variables (months/days): check for negative values\n",
    "# 14. Collect and print all quality issues found\n",
    "#\n",
    "# TODO: Sample matching between datasets:\n",
    "# 15. Create sets of sample IDs from expression data (columns) and clinical data\n",
    "# 16. Find intersection (common samples) and differences\n",
    "# 17. Calculate overlap percentage\n",
    "# 18. Print matching statistics and any warnings about low overlap\n",
    "#\n",
    "# TODO: Summarize quality assessment:\n",
    "# 19. Provide overall quality summary\n",
    "# 20. Recommend next steps based on issues found\n",
    "#\n",
    "# Expected output: Comprehensive quality report with actionable recommendations\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"DATA QUALITY ASSESSMENT\")\n",
    "# print(\"=\"*50)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1642c3d8",
   "metadata": {},
   "source": [
    "## 4. Summary and Key Findings\n",
    "\n",
    "Let's summarize the key findings from our data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dd6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \udcdd ACTIVITY 18: Save Exploration Results (Optional)\n",
    "#\n",
    "# Your task: Save exploration results for future reference and analysis\n",
    "# Note: This is an optional activity for organizing your findings\n",
    "#\n",
    "# TODO: Create results directory structure:\n",
    "# 1. Use os.makedirs('../results/exploration', exist_ok=True) to create directory\n",
    "# 2. This will store your exploration outputs for later use\n",
    "#\n",
    "# TODO: Create and save exploration summary dictionary:\n",
    "# 3. Create exploration_summary dictionary with sections:\n",
    "#    - dataset_info: shapes and missing value percentages\n",
    "#    - expression_stats: basic statistics (if expression data available)  \n",
    "#    - clinical_variables: lists of numerical and categorical variables\n",
    "# 4. Handle cases where expression_data might not be available\n",
    "#\n",
    "# TODO: Save gene statistics (if expression data available):\n",
    "# 5. Create DataFrame with gene-level statistics:\n",
    "#    - gene names, mean, std, variance, min, max for each gene\n",
    "# 6. Save as CSV: '../results/exploration/gene_statistics.csv'\n",
    "# 7. Use .to_csv(filename, index=False)\n",
    "#\n",
    "# TODO: Save sample statistics (if expression data available):\n",
    "# 8. Create DataFrame with sample-level statistics:\n",
    "#    - sample names, mean, std, median, quartiles for each sample\n",
    "# 9. Save as CSV: '../results/exploration/sample_statistics.csv'\n",
    "#\n",
    "# TODO: Save clinical data summary:\n",
    "# 10. Create dictionary with value counts for each categorical variable\n",
    "# 11. Use json.dump() to save as '../results/exploration/clinical_summary.json'\n",
    "# 12. Handle potential JSON serialization issues with default=str\n",
    "#\n",
    "# TODO: Print confirmation messages:\n",
    "# 13. List all files that were successfully saved\n",
    "# 14. Provide guidance on what to do next\n",
    "# 15. Mention the next notebook in the sequence\n",
    "#\n",
    "# Expected output: Saved files and confirmation messages\n",
    "\n",
    "# Write your code below:\n",
    "# import os\n",
    "# os.makedirs('../results/exploration', exist_ok=True)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b02321",
   "metadata": {},
   "source": [
    "## 5. Save Exploration Results\n",
    "\n",
    "Let's save some key exploration results for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e363b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory if it doesn't exist\n",
    "os.makedirs('../results/exploration', exist_ok=True)\n",
    "\n",
    "# Save data summaries\n",
    "exploration_summary = {\n",
    "    'dataset_info': {\n",
    "        'expression_shape': expression_data.shape,\n",
    "        'clinical_shape': clinical_data.shape,\n",
    "        'expression_missing_pct': (expression_data.isnull().sum().sum() / expression_data.size) * 100,\n",
    "        'clinical_missing_pct': (clinical_data.isnull().sum().sum() / clinical_data.size) * 100\n",
    "    },\n",
    "    'expression_stats': {\n",
    "        'mean': float(expression_data.values.mean()),\n",
    "        'std': float(expression_data.values.std()),\n",
    "        'min': float(expression_data.values.min()),\n",
    "        'max': float(expression_data.values.max()),\n",
    "        'low_variance_genes': int((expression_data.var(axis=1) < 0.1).sum())\n",
    "    },\n",
    "    'clinical_variables': {\n",
    "        'numerical': numerical_vars,\n",
    "        'categorical': categorical_vars\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save gene variance information\n",
    "gene_stats = pd.DataFrame({\n",
    "    'gene': expression_data.index,\n",
    "    'mean': expression_data.mean(axis=1),\n",
    "    'std': expression_data.std(axis=1),\n",
    "    'variance': expression_data.var(axis=1),\n",
    "    'min': expression_data.min(axis=1),\n",
    "    'max': expression_data.max(axis=1)\n",
    "})\n",
    "\n",
    "gene_stats.to_csv('../results/exploration/gene_statistics.csv', index=False)\n",
    "\n",
    "# Save sample statistics\n",
    "sample_stats = pd.DataFrame({\n",
    "    'sample': expression_data.columns,\n",
    "    'mean': expression_data.mean(axis=0),\n",
    "    'std': expression_data.std(axis=0),\n",
    "    'median': expression_data.median(axis=0),\n",
    "    'q25': expression_data.quantile(0.25, axis=0),\n",
    "    'q75': expression_data.quantile(0.75, axis=0)\n",
    "})\n",
    "\n",
    "sample_stats.to_csv('../results/exploration/sample_statistics.csv', index=False)\n",
    "\n",
    "# Save clinical data summary\n",
    "if len(categorical_vars) > 0:\n",
    "    clinical_summary = {}\n",
    "    for var in categorical_vars:\n",
    "        if var in clinical_data.columns:\n",
    "            clinical_summary[var] = clinical_data[var].value_counts().to_dict()\n",
    "    \n",
    "    import json\n",
    "    with open('../results/exploration/clinical_summary.json', 'w') as f:\n",
    "        json.dump(clinical_summary, f, indent=2, default=str)\n",
    "\n",
    "print(\"Exploration results saved to:\")\n",
    "print(\"  ‚Ä¢ ../results/exploration/gene_statistics.csv\")\n",
    "print(\"  ‚Ä¢ ../results/exploration/sample_statistics.csv\")\n",
    "print(\"  ‚Ä¢ ../results/exploration/clinical_summary.json\")\n",
    "\n",
    "print(\"\\nüìù Ready for the next notebook: 02_data_preprocessing.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e6f4d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Learning Summary\n",
    "\n",
    "In this notebook, you have learned:\n",
    "\n",
    "### ‚úÖ **Completed Tasks:**\n",
    "1. **Data Loading**: Successfully loaded transcriptomics and clinical data\n",
    "2. **Missing Values Analysis**: Identified and quantified missing data patterns\n",
    "3. **Clinical Data Exploration**: Analyzed patient characteristics and sample types\n",
    "4. **Expression Data Analysis**: Examined gene expression distributions and quality\n",
    "5. **Data Quality Assessment**: Identified potential issues and outliers\n",
    "6. **Sample Matching**: Evaluated overlap between datasets\n",
    "\n",
    "### üéØ **Key Insights:**\n",
    "- Understanding the structure and characteristics of genomics datasets\n",
    "- Importance of data quality assessment in bioinformatics\n",
    "- Common issues in transcriptomics data (missing values, low variance genes, outliers)\n",
    "- Clinical variables that may be important for risk classification\n",
    "\n",
    "### üîÑ **Next Steps:**\n",
    "In the next notebook (`02_data_preprocessing.ipynb`), we will:\n",
    "1. Handle missing values and outliers\n",
    "2. Normalize gene expression data\n",
    "3. Filter low-quality genes and samples\n",
    "4. Create train/validation/test splits\n",
    "5. Prepare data for machine learning modeling\n",
    "\n",
    "---\n",
    "\n",
    "**Great job completing the data exploration phase! üéâ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
