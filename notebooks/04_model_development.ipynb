{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcbaf2fa",
   "metadata": {},
   "source": [
    "# Machine Learning Course: Model Development & Clinical Evaluation\n",
    "\n",
    "## Notebook 4: Risk Prediction Models and Clinical Validation\n",
    "\n",
    "> ** Prerequisites:** Complete notebooks 1-3 first. This notebook loads the optimized feature sets from notebook 3 and focuses exclusively on model training, evaluation, and clinical validation.\n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "1. **Train time-independent classification models** for risk prediction (Logistic, SVM, RF, GBM, NN)\n",
    "2. **Train time-dependent survival models** using Cox regression and Random Survival Forests\n",
    "3. **Evaluate models using clinical metrics**: C-index, precision in low-risk, calibration\n",
    "4. **Stratify patients into risk groups** and validate clinical utility\n",
    "5. **Compare and select optimal models** for clinical deployment\n",
    "6. **Export production-ready models** with implementation materials\n",
    "\n",
    "### Data Flow\n",
    "- **Input**: Optimized feature sets from `03_feature_selection.ipynb`\n",
    "- **Processing**: Model training, hyperparameter tuning, clinical evaluation\n",
    "- **Output**: Production-ready risk prediction models\n",
    "\n",
    "### Clinical Evaluation Framework\n",
    "- **C-index (Concordance Index)**: Primary metric for ranking predictions\n",
    "- **Precision in Low-Risk Group**: Identifying patients who truly don't need aggressive treatment\n",
    "- **Calibration**: Agreement between predicted and observed event rates\n",
    "- **Risk Stratification**: Statistical validation of low/medium/high risk groups\n",
    "- **Survival Curves**: Kaplan-Meier analysis by risk group (if survival data available)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5157cd0",
   "metadata": {},
   "source": [
    "## 1. Load Data and Selected Features\n",
    "\n",
    "Load the preprocessed data and optimized feature sets from notebook 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f2c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 1: Load Selected Features and Preprocessed Data\n",
    "#\n",
    "# Your task: Load the optimized feature sets from notebook 3 and preprocessed data\n",
    "#\n",
    "# TODO: Import required libraries:\n",
    "# 1. Import pandas, numpy, matplotlib.pyplot, seaborn\n",
    "# 2. Import sklearn models: LogisticRegression, SVC, RandomForestClassifier, GradientBoostingClassifier\n",
    "# 3. Import sklearn.neural_network: MLPClassifier\n",
    "# 4. Import sklearn.model_selection: cross_val_score, StratifiedKFold, GridSearchCV\n",
    "# 5. Import sklearn.metrics: roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# 6. Import sklearn.calibration: calibration_curve, CalibratedClassifierCV\n",
    "# 7. Try importing lifelines: CoxPHFitter, KaplanMeierFitter, concordance_index, logrank_test\n",
    "# 8. Import scipy.stats: chi2_contingency\n",
    "# 9. Import joblib, time\n",
    "#\n",
    "# TODO: Load feature selection results from notebook 3:\n",
    "# 10. Load from '../results/feature_selection/':\n",
    "#     - ensemble_minimal.csv (high-confidence features)\n",
    "#     - ensemble_balanced.csv (recommended feature set)\n",
    "#     - ensemble_comprehensive.csv (maximum coverage)\n",
    "# 11. Choose which feature set to use for modeling (typically balanced)\n",
    "#\n",
    "# TODO: Load preprocessed data from notebook 2:\n",
    "# 12. Load from '../results/preprocessing/':\n",
    "#     - X_train_scaled.csv, X_val_scaled.csv, X_test_scaled.csv\n",
    "#     - y_train.csv, y_val.csv, y_test.csv\n",
    "# 13. Filter X datasets to only include selected features\n",
    "#\n",
    "# TODO: Verify data alignment:\n",
    "# 14. Check shapes: X_train, X_val, X_test, y_train, y_val, y_test\n",
    "# 15. Confirm target variables include RFS_MONTHS and RFS_STATUS (from preprocessing)\n",
    "# 16. Verify no missing values in final datasets\n",
    "#\n",
    "# TODO: Display data summary:\n",
    "# 17. Print number of features selected\n",
    "# 18. Print dataset sizes (train/val/test)\n",
    "# 19. Print target distribution\n",
    "# 20. Confirm data is ready for modeling\n",
    "#\n",
    "# Expected output: Loaded feature sets and data ready for model training\n",
    "\n",
    "# Write your code below:\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# \n",
    "# # Load selected features from notebook 3\n",
    "# feature_selection_dir = '../results/feature_selection/'\n",
    "# selected_features_df = pd.read_csv(f'{feature_selection_dir}ensemble_balanced.csv')\n",
    "# selected_features = selected_features_df['feature'].tolist() if 'feature' in selected_features_df.columns else selected_features_df.iloc[:, 0].tolist()\n",
    "# \n",
    "# # Load preprocessed data from notebook 2\n",
    "# preprocessing_dir = '../results/preprocessing/'\n",
    "# X_train = pd.read_csv(f'{preprocessing_dir}X_train_scaled.csv', index_col=0)[selected_features]\n",
    "# X_val = pd.read_csv(f'{preprocessing_dir}X_val_scaled.csv', index_col=0)[selected_features]\n",
    "# X_test = pd.read_csv(f'{preprocessing_dir}X_test_scaled.csv', index_col=0)[selected_features]\n",
    "# y_train = pd.read_csv(f'{preprocessing_dir}y_train.csv', index_col=0)\n",
    "# y_val = pd.read_csv(f'{preprocessing_dir}y_val.csv', index_col=0)\n",
    "# y_test = pd.read_csv(f'{preprocessing_dir}y_test.csv', index_col=0)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499dc1f",
   "metadata": {},
   "source": [
    "## 2. Time-Independent Classification Models\n",
    "\n",
    "Train multiple classification algorithms to predict risk without time-to-event information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362461e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 2: Train Time-Independent Classification Models\n",
    "#\n",
    "# Your task: Train multiple classification algorithms for risk prediction\n",
    "#\n",
    "# TODO: Set up model training framework:\n",
    "# 1. Define target variable: y_binary = y_train['RFS_STATUS'] (0=no recurrence, 1=recurrence)\n",
    "# 2. Initialize results storage: model_results = {}\n",
    "# 3. Set up cross-validation: cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#\n",
    "# TODO: Define models to train:\n",
    "# 4. Create dictionary of models:\n",
    "#    models = {\n",
    "#        'Logistic Regression (L1)': LogisticRegression(penalty='l1', solver='liblinear', C=1.0, random_state=42),\n",
    "#        'Logistic Regression (L2)': LogisticRegression(penalty='l2', C=1.0, max_iter=1000, random_state=42),\n",
    "#        'SVM (RBF)': SVC(kernel='rbf', C=1.0, probability=True, random_state=42),\n",
    "#        'SVM (Linear)': SVC(kernel='linear', C=1.0, probability=True, random_state=42),\n",
    "#        'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "#        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "#        'Neural Network': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "#    }\n",
    "#\n",
    "# TODO: Train and evaluate each model:\n",
    "# 5. For each model in models:\n",
    "#    - Fit on training data: model.fit(X_train, y_binary)\n",
    "#    - Get training predictions: train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "#    - Get validation predictions: val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "#    - Calculate training AUC: train_auc = roc_auc_score(y_binary, train_pred_proba)\n",
    "#    - Calculate validation AUC: val_auc = roc_auc_score(y_val['RFS_STATUS'], val_pred_proba)\n",
    "#    - Perform cross-validation: cv_scores = cross_val_score(model, X_train, y_binary, cv=cv, scoring='roc_auc')\n",
    "#    - Store results: model_results[model_name] = {'train_auc': ..., 'val_auc': ..., 'cv_mean': ..., 'cv_std': ...}\n",
    "#\n",
    "# TODO: Calculate additional metrics:\n",
    "# 6. For each model's validation predictions:\n",
    "#    - Calculate precision, recall, F1 at optimal threshold\n",
    "#    - Calculate confusion matrix\n",
    "#    - Store metrics in model_results\n",
    "#\n",
    "# TODO: Visualize model performance:\n",
    "# 7. Create comparison plot: model performance (AUC) with error bars\n",
    "# 8. Create ROC curves for top 3 models on validation set\n",
    "# 9. Print performance summary table\n",
    "#\n",
    "# TODO: Identify top models:\n",
    "# 10. Sort models by validation AUC\n",
    "# 11. Select top 3 models for further analysis\n",
    "# 12. Print top model summary\n",
    "#\n",
    "# Expected output: Trained classification models with performance comparison\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"TIME-INDEPENDENT CLASSIFICATION MODELS\")\n",
    "# print(\"=\"*60)\n",
    "# \n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424246d4",
   "metadata": {},
   "source": [
    "## 3. Time-Dependent Survival Models\n",
    "\n",
    "Train survival analysis models that incorporate time-to-event information using RFS_MONTHS and RFS_STATUS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 3: Train Time-Dependent Survival Models\n",
    "#\n",
    "# Your task: Train Cox regression and survival models using RFS data from preprocessing\n",
    "#\n",
    "# TODO: Check survival library availability:\n",
    "# 1. Try importing: from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "# 2. Try importing: from lifelines.utils import concordance_index\n",
    "# 3. Set flag: lifelines_available = True/False\n",
    "# 4. If not available, provide installation guidance\n",
    "#\n",
    "# TODO: Prepare survival data:\n",
    "# 5. Extract survival variables from y_train:\n",
    "#    - duration_train = y_train['RFS_MONTHS']\n",
    "#    - event_train = y_train['RFS_STATUS']\n",
    "# 6. Create survival DataFrame: survival_df_train = pd.concat([X_train, duration_train, event_train], axis=1)\n",
    "# 7. Handle any missing or zero survival times\n",
    "# 8. Verify data format: duration > 0, event in {0, 1}\n",
    "#\n",
    "# TODO: Train Cox Proportional Hazards model (if lifelines available):\n",
    "# 9. Create Cox model: cph = CoxPHFitter()\n",
    "# 10. Fit model: cph.fit(survival_df_train, duration_col='RFS_MONTHS', event_col='RFS_STATUS')\n",
    "# 11. Print model summary: cph.print_summary()\n",
    "# 12. Get concordance index: c_index_train = cph.concordance_index_\n",
    "#\n",
    "# TODO: Evaluate Cox model on validation set:\n",
    "# 13. Prepare validation survival data\n",
    "# 14. Calculate risk scores: risk_scores_val = cph.predict_partial_hazard(X_val)\n",
    "# 15. Calculate validation C-index: c_index_val = concordance_index(y_val['RFS_MONTHS'], -risk_scores_val, y_val['RFS_STATUS'])\n",
    "# 16. Compare train vs validation C-index\n",
    "#\n",
    "# TODO: Extract hazard ratios for top features:\n",
    "# 17. Get hazard ratios: hazard_ratios = cph.hazard_ratios_\n",
    "# 18. Sort by magnitude: top_hr = hazard_ratios.abs().sort_values(ascending=False).head(20)\n",
    "# 19. Visualize top hazard ratios with confidence intervals\n",
    "# 20. Interpret: HR > 1 means increased risk, HR < 1 means decreased risk\n",
    "#\n",
    "# TODO: Alternative if lifelines not available:\n",
    "# 21. Use logistic regression with RFS_STATUS as proxy\n",
    "# 22. Note limitations of this approach\n",
    "# 23. Recommend installing lifelines for proper survival analysis\n",
    "#\n",
    "# TODO: Save Cox model results:\n",
    "# 24. Store C-index, hazard ratios, and predictions\n",
    "# 25. Add to model_results dictionary\n",
    "# 26. Compare C-index with classification model AUCs\n",
    "#\n",
    "# Expected output: Cox regression model with C-index and hazard ratio analysis\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"TIME-DEPENDENT SURVIVAL MODELS\")\n",
    "# print(\"=\"*60)\n",
    "# \n",
    "# try:\n",
    "#     from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "#     from lifelines.utils import concordance_index\n",
    "#     lifelines_available = True\n",
    "#     print(\"‚úì Lifelines library available\")\n",
    "# except ImportError:\n",
    "#     lifelines_available = False\n",
    "#     print(\"‚ö†Ô∏è  Lifelines not available\")\n",
    "#     print(\"Install with: pip install lifelines\")\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a390861",
   "metadata": {},
   "source": [
    "## 4. Clinical Evaluation: C-index and Precision in Low-Risk\n",
    "\n",
    "Calculate clinical metrics including C-index and precision in low-risk group identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 4: Clinical Evaluation Metrics\n",
    "#\n",
    "# Your task: Calculate C-index and precision in low-risk group for all models\n",
    "#\n",
    "# TODO: Set up clinical evaluation framework:\n",
    "# 1. Create results DataFrame: clinical_metrics = pd.DataFrame(columns=['Model', 'C-index', 'Precision_Low_Risk', 'Precision_High_Risk'])\n",
    "# 2. Define low-risk threshold: typically bottom 25% or 33% of risk scores\n",
    "# 3. Define high-risk threshold: typically top 25% or 33% of risk scores\n",
    "#\n",
    "# TODO: Calculate C-index for all models:\n",
    "# 4. For classification models: C-index = AUC (equivalent for binary outcomes)\n",
    "# 5. For Cox models: use concordance_index from lifelines\n",
    "# 6. Store C-index values for each model\n",
    "#\n",
    "# TODO: Calculate precision in low-risk group:\n",
    "# 7. For each model's validation predictions:\n",
    "#    - Define low-risk patients: bottom 25% of risk scores\n",
    "#    - low_risk_threshold = np.percentile(risk_scores, 25)\n",
    "#    - low_risk_mask = risk_scores <= low_risk_threshold\n",
    "#    - Calculate precision: true_negatives / predicted_low_risk\n",
    "#    - precision_low = np.sum((y_val['RFS_STATUS'] == 0) & low_risk_mask) / np.sum(low_risk_mask)\n",
    "# 8. This measures: \"Of patients predicted as low-risk, what % truly have no recurrence?\"\n",
    "#\n",
    "# TODO: Calculate precision in high-risk group:\n",
    "# 9. Define high-risk patients: top 25% of risk scores\n",
    "# 10. high_risk_threshold = np.percentile(risk_scores, 75)\n",
    "# 11. high_risk_mask = risk_scores >= high_risk_threshold\n",
    "# 12. Calculate precision: true_positives / predicted_high_risk\n",
    "# 13. precision_high = np.sum((y_val['RFS_STATUS'] == 1) & high_risk_mask) / np.sum(high_risk_mask)\n",
    "#\n",
    "# TODO: Calculate calibration metrics:\n",
    "# 14. For models with probability outputs:\n",
    "#     - Use calibration_curve: fraction_of_positives, mean_predicted_value = calibration_curve(y_true, y_prob, n_bins=10)\n",
    "#     - Calculate Brier score: brier_score = np.mean((y_prob - y_true) ** 2)\n",
    "#     - Lower Brier score = better calibration\n",
    "#\n",
    "# TODO: Create comprehensive metrics table:\n",
    "# 15. Combine all metrics for each model:\n",
    "#     - Model name, C-index, Precision (Low), Precision (High), Brier Score\n",
    "# 16. Sort by C-index or precision in low-risk\n",
    "# 17. Identify best models for different objectives\n",
    "#\n",
    "# TODO: Visualize clinical metrics:\n",
    "# 18. Create bar plot: C-index comparison across models\n",
    "# 19. Create scatter plot: C-index vs Precision in Low-Risk\n",
    "# 20. Create calibration plots for top 3 models\n",
    "# 21. Highlight clinical utility trade-offs\n",
    "#\n",
    "# TODO: Interpret clinical relevance:\n",
    "# 22. Explain what C-index values mean (>0.7 good, >0.8 excellent)\n",
    "# 23. Explain precision in low-risk importance for treatment de-escalation\n",
    "# 24. Identify models suitable for clinical decision support\n",
    "#\n",
    "# Expected output: Clinical metrics table with C-index and precision analysis\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"CLINICAL EVALUATION METRICS\")\n",
    "# print(\"=\"*60)\n",
    "# \n",
    "# from sklearn.calibration import calibration_curve\n",
    "# \n",
    "# def calculate_precision_in_risk_groups(y_true, risk_scores, low_percentile=25, high_percentile=75):\n",
    "#     \"\"\"Calculate precision in low and high risk groups\"\"\"\n",
    "#     low_threshold = np.percentile(risk_scores, low_percentile)\n",
    "#     high_threshold = np.percentile(risk_scores, high_percentile)\n",
    "#     \n",
    "#     # Low risk precision (Negative Predictive Value-like)\n",
    "#     low_risk_mask = risk_scores <= low_threshold\n",
    "#     precision_low = np.sum((y_true == 0) & low_risk_mask) / np.sum(low_risk_mask) if np.sum(low_risk_mask) > 0 else 0\n",
    "#     \n",
    "#     # High risk precision (Positive Predictive Value)\n",
    "#     high_risk_mask = risk_scores >= high_threshold\n",
    "#     precision_high = np.sum((y_true == 1) & high_risk_mask) / np.sum(high_risk_mask) if np.sum(high_risk_mask) > 0 else 0\n",
    "#     \n",
    "#     return precision_low, precision_high\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d0008",
   "metadata": {},
   "source": [
    "## 5. Risk Stratification and Survival Analysis\n",
    "\n",
    "Create low/medium/high risk groups and validate their clinical utility using survival curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe65c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 5: Risk Stratification and Kaplan-Meier Analysis\n",
    "#\n",
    "# Your task: Create risk groups and validate using survival curves\n",
    "#\n",
    "# TODO: Select best model for risk stratification:\n",
    "# 1. Based on Activity 4, select model with best balance of C-index and precision\n",
    "# 2. Get risk scores on validation set: risk_scores = best_model.predict_proba(X_val)[:, 1]\n",
    "#\n",
    "# TODO: Create risk groups using tertiles:\n",
    "# 3. Calculate tertile thresholds: percentiles = np.percentile(risk_scores, [33.33, 66.67])\n",
    "# 4. Assign risk groups:\n",
    "#    - risk_groups = np.where(risk_scores <= percentiles[0], 'Low',\n",
    "#                             np.where(risk_scores <= percentiles[1], 'Medium', 'High'))\n",
    "# 5. Create risk group DataFrame with scores and groups\n",
    "#\n",
    "# TODO: Analyze risk group characteristics:\n",
    "# 6. Calculate event rates by risk group:\n",
    "#    - For each group: event_rate = mean(y_val['RFS_STATUS'])\n",
    "# 7. Test statistical significance: chi2, p_value = chi2_contingency(contingency_table)\n",
    "# 8. Calculate sample sizes per group\n",
    "# 9. Verify monotonic trend: low < medium < high event rates\n",
    "#\n",
    "# TODO: Create Kaplan-Meier survival curves (if lifelines available):\n",
    "# 10. For each risk group:\n",
    "#     - kmf = KaplanMeierFitter()\n",
    "#     - kmf.fit(durations=y_val['RFS_MONTHS'][risk_groups=='Low'], \n",
    "#               event_observed=y_val['RFS_STATUS'][risk_groups=='Low'],\n",
    "#               label='Low Risk')\n",
    "#     - Plot survival curve: kmf.plot()\n",
    "# 11. Repeat for Medium and High risk groups\n",
    "# 12. Create combined plot with all three curves\n",
    "#\n",
    "# TODO: Perform log-rank test:\n",
    "# 13. Test survival curve differences:\n",
    "#     - from lifelines.statistics import logrank_test\n",
    "#     - Compare Low vs High: logrank_test(durations_low, durations_high, events_low, events_high)\n",
    "#     - Print p-value and test statistic\n",
    "# 14. Test pairwise differences: Low vs Medium, Medium vs High\n",
    "# 15. Confirm significant separation (p < 0.05)\n",
    "#\n",
    "# TODO: Calculate hazard ratios between groups:\n",
    "# 16. Use Cox regression with risk groups as categorical variable\n",
    "# 17. Calculate HR for Medium vs Low, High vs Low\n",
    "# 18. Display with confidence intervals\n",
    "#\n",
    "# TODO: Visualize risk stratification:\n",
    "# 19. Create figure with 3 panels:\n",
    "#     - Panel 1: Risk score distribution by group (violin plot)\n",
    "#     - Panel 2: Event rates by group (bar plot with CI)\n",
    "#     - Panel 3: Kaplan-Meier curves by group\n",
    "# 20. Add statistical test results to plots\n",
    "#\n",
    "# TODO: Create risk group summary table:\n",
    "# 21. For each risk group:\n",
    "#     - N patients, Event rate, Median survival time\n",
    "#     - Hazard ratio vs Low risk (reference)\n",
    "#     - 95% confidence intervals\n",
    "#\n",
    "# TODO: Validate risk thresholds:\n",
    "# 22. Test different stratification strategies (quartiles, quintiles)\n",
    "# 23. Compare clinical utility of different strategies\n",
    "# 24. Select optimal stratification for clinical use\n",
    "#\n",
    "# Expected output: Risk-stratified patient groups with validated survival curves\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"RISK STRATIFICATION AND SURVIVAL ANALYSIS\")\n",
    "# print(\"=\"*60)\n",
    "# \n",
    "# from scipy.stats import chi2_contingency\n",
    "# \n",
    "# # Create risk groups\n",
    "# best_model_name = 'Random Forest'  # Replace with actual best model\n",
    "# risk_scores = model_results[best_model_name]['val_predictions']\n",
    "# \n",
    "# percentiles = np.percentile(risk_scores, [33.33, 66.67])\n",
    "# risk_groups = np.where(risk_scores <= percentiles[0], 'Low',\n",
    "#                       np.where(risk_scores <= percentiles[1], 'Medium', 'High'))\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35824de",
   "metadata": {},
   "source": [
    "## 6. Model Selection and Hyperparameter Tuning\n",
    "\n",
    "Select the best model and optimize hyperparameters using grid search with clinical metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43094ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 6: Model Selection and Hyperparameter Optimization\n",
    "#\n",
    "# Your task: Select best model and optimize its hyperparameters\n",
    "#\n",
    "# TODO: Review model performance across all activities:\n",
    "# 1. Create comprehensive comparison table:\n",
    "#    - Model, Train AUC, Val AUC, C-index, Precision Low-Risk, Precision High-Risk\n",
    "# 2. Rank models by validation C-index\n",
    "# 3. Identify top 3 candidates for hyperparameter tuning\n",
    "#\n",
    "# TODO: Set up hyperparameter tuning framework:\n",
    "# 4. Choose top model (e.g., Random Forest or Gradient Boosting)\n",
    "# 5. Define parameter grid:\n",
    "#    - For Random Forest: n_estimators=[50, 100, 200], max_depth=[5, 10, 15, None], min_samples_split=[2, 5, 10]\n",
    "#    - For GBM: n_estimators=[50, 100, 200], learning_rate=[0.01, 0.1, 0.2], max_depth=[3, 5, 7]\n",
    "#    - For Logistic: C=[0.01, 0.1, 1, 10], penalty=['l1', 'l2']\n",
    "#\n",
    "# TODO: Implement GridSearchCV with clinical scoring:\n",
    "# 6. Create GridSearchCV:\n",
    "#    - grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "# 7. Fit on training data: grid_search.fit(X_train, y_train['RFS_STATUS'])\n",
    "# 8. Get best parameters: best_params = grid_search.best_params_\n",
    "# 9. Get best score: best_cv_score = grid_search.best_score_\n",
    "#\n",
    "# TODO: Evaluate optimized model:\n",
    "# 10. Get best model: best_model = grid_search.best_estimator_\n",
    "# 11. Predict on validation: val_pred = best_model.predict_proba(X_val)[:, 1]\n",
    "# 12. Calculate validation metrics: AUC, C-index, precision in low/high risk\n",
    "# 13. Compare to baseline (non-tuned) model performance\n",
    "#\n",
    "# TODO: Feature importance analysis:\n",
    "# 14. Extract feature importances from best model\n",
    "# 15. Rank features by importance\n",
    "# 16. Visualize top 20 features\n",
    "# 17. Interpret clinical relevance of top features\n",
    "#\n",
    "# TODO: Model calibration:\n",
    "# 18. Check if model needs calibration:\n",
    "#     - Plot calibration curve\n",
    "#     - Calculate calibration slope and intercept\n",
    "# 19. If poorly calibrated, apply calibration:\n",
    "#     - calibrated_model = CalibratedClassifierCV(best_model, method='sigmoid', cv=5)\n",
    "#     - calibrated_model.fit(X_train, y_train['RFS_STATUS'])\n",
    "#     - Evaluate calibration improvement\n",
    "#\n",
    "# TODO: Create final model comparison:\n",
    "# 20. Compare baseline vs tuned vs calibrated versions\n",
    "# 21. Select final model based on:\n",
    "#     - Validation C-index (primary)\n",
    "#     - Precision in low-risk (secondary)\n",
    "#     - Calibration quality (tertiary)\n",
    "# 22. Document selection rationale\n",
    "#\n",
    "# Expected output: Optimized final model with feature importance and calibration\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"MODEL SELECTION AND HYPERPARAMETER TUNING\")\n",
    "# print(\"=\"*60)\n",
    "# \n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "# \n",
    "# # Define parameter grid for top model\n",
    "# param_grid_rf = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [5, 10, 15, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c876e8",
   "metadata": {},
   "source": [
    "## 7. Final Model Validation on Test Set\n",
    "\n",
    "Validate the selected model on the held-out test set and prepare for clinical deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù ACTIVITY 7: Final Model Validation and Deployment Preparation\n",
    "#\n",
    "# Your task: Validate final model on test set and create deployment package\n",
    "#\n",
    "# TODO: Perform final test set evaluation:\n",
    "# 1. Get final optimized model from Activity 6\n",
    "# 2. Make predictions on test set: test_pred = final_model.predict_proba(X_test)[:, 1]\n",
    "# 3. Calculate test metrics:\n",
    "#    - Test C-index: roc_auc_score(y_test['RFS_STATUS'], test_pred)\n",
    "#    - Precision in low-risk: using calculate_precision_in_risk_groups()\n",
    "#    - Test calibration: calibration_curve on test set\n",
    "#\n",
    "# TODO: Compare performance across all splits:\n",
    "# 4. Create summary table:\n",
    "#    - Metric | Train | Validation | Test\n",
    "#    - C-index | ... | ... | ...\n",
    "#    - Precision Low-Risk | ... | ... | ...\n",
    "#    - Precision High-Risk | ... | ... | ...\n",
    "# 5. Check for overfitting: large train-test gaps\n",
    "# 6. Assess generalization: similar val and test performance\n",
    "#\n",
    "# TODO: Create final risk stratification on test set:\n",
    "# 7. Apply risk group thresholds from validation to test data\n",
    "# 8. Calculate event rates by risk group on test set\n",
    "# 9. Create Kaplan-Meier curves for test risk groups\n",
    "# 10. Perform log-rank test to confirm risk group separation\n",
    "#\n",
    "# TODO: Bootstrap confidence intervals:\n",
    "# 11. Calculate bootstrap CI for test C-index:\n",
    "#     - Resample test set 1000 times\n",
    "#     - Calculate C-index on each bootstrap sample\n",
    "#     - Report mean and 95% CI\n",
    "# 12. Calculate CI for precision metrics\n",
    "#\n",
    "# TODO: Feature importance and interpretation:\n",
    "# 13. Extract final feature importances/coefficients\n",
    "# 14. Create visualization of top 20 features\n",
    "# 15. Provide clinical interpretation for each top feature\n",
    "# 16. Document biological relevance\n",
    "#\n",
    "# TODO: Create clinical deployment package:\n",
    "# 17. Save final model: joblib.dump(final_model, '../results/models/final_model.pkl')\n",
    "# 18. Save feature list: pd.Series(selected_features).to_csv('../results/models/model_features.csv')\n",
    "# 19. Save risk thresholds: json.dump(risk_thresholds, open('../results/models/risk_thresholds.json', 'w'))\n",
    "# 20. Save preprocessing info: document normalization parameters used\n",
    "#\n",
    "# TODO: Create prediction function for deployment:\n",
    "# 21. Write function:\n",
    "#     def predict_patient_risk(patient_features):\n",
    "#         # Load model\n",
    "#         # Apply preprocessing\n",
    "#         # Make prediction\n",
    "#         # Assign risk group\n",
    "#         # Return risk score and group\n",
    "# 22. Test function with sample patient data\n",
    "#\n",
    "# TODO: Generate model documentation:\n",
    "# 23. Create model card with:\n",
    "#     - Model type and hyperparameters\n",
    "#     - Training dataset characteristics\n",
    "#     - Performance metrics (C-index, precision)\n",
    "#     - Feature requirements\n",
    "#     - Risk group definitions\n",
    "#     - Clinical interpretation guidelines\n",
    "# 24. Document limitations and appropriate use cases\n",
    "#\n",
    "# TODO: Create final report:\n",
    "# 25. Executive summary: one-page overview\n",
    "# 26. Performance metrics across all splits\n",
    "# 27. Risk stratification validation results\n",
    "# 28. Feature importance and interpretation\n",
    "# 29. Deployment guidelines\n",
    "# 30. Monitoring and maintenance recommendations\n",
    "#\n",
    "# Expected output: Validated production-ready model with complete deployment package\n",
    "\n",
    "# Write your code below:\n",
    "# print(\"FINAL MODEL VALIDATION AND DEPLOYMENT\")\n",
    "# print(\"=\"*60)\n",
    "# \n",
    "# import joblib\n",
    "# import json\n",
    "# \n",
    "# # Test set evaluation\n",
    "# test_pred = final_model.predict_proba(X_test)[:, 1]\n",
    "# test_c_index = roc_auc_score(y_test['RFS_STATUS'], test_pred)\n",
    "# test_precision_low, test_precision_high = calculate_precision_in_risk_groups(\n",
    "#     y_test['RFS_STATUS'].values, test_pred\n",
    "# )\n",
    "# \n",
    "# print(f\"\\nFinal Test Set Performance:\")\n",
    "# print(f\"  C-index: {test_c_index:.3f}\")\n",
    "# print(f\"  Precision (Low-Risk): {test_precision_low:.3f}\")\n",
    "# print(f\"  Precision (High-Risk): {test_precision_high:.3f}\")\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce667fc7",
   "metadata": {},
   "source": [
    "##  Coding Hints and Templates\n",
    "\n",
    "Need help getting started? Here are code templates for model development:\n",
    "\n",
    "### üìã **Template 1: Training Classification Models**\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train['RFS_STATUS'])\n",
    "val_pred = model.predict_proba(X_val)[:, 1]\n",
    "auc = roc_auc_score(y_val['RFS_STATUS'], val_pred)\n",
    "```\n",
    "\n",
    "### üìã **Template 2: Cox Regression**\n",
    "```python\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "cph = CoxPHFitter()\n",
    "survival_df = pd.concat([X_train, y_train[['RFS_MONTHS', 'RFS_STATUS']]], axis=1)\n",
    "cph.fit(survival_df, duration_col='RFS_MONTHS', event_col='RFS_STATUS')\n",
    "print(f\"C-index: {cph.concordance_index_:.3f}\")\n",
    "```\n",
    "\n",
    "### üìã **Template 3: Precision in Low-Risk**\n",
    "```python\n",
    "def calculate_low_risk_precision(y_true, risk_scores, percentile=25):\n",
    "    threshold = np.percentile(risk_scores, percentile)\n",
    "    low_risk_mask = risk_scores <= threshold\n",
    "    true_negatives = np.sum((y_true == 0) & low_risk_mask)\n",
    "    predicted_low = np.sum(low_risk_mask)\n",
    "    return true_negatives / predicted_low if predicted_low > 0 else 0\n",
    "```\n",
    "\n",
    "### üìã **Template 4: Kaplan-Meier Curves**\n",
    "```python\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "kmf = KaplanMeierFitter()\n",
    "for risk_group in ['Low', 'Medium', 'High']:\n",
    "    mask = risk_groups == risk_group\n",
    "    kmf.fit(y_val['RFS_MONTHS'][mask], y_val['RFS_STATUS'][mask], label=risk_group)\n",
    "    kmf.plot()\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Survival Probability')\n",
    "```\n",
    "\n",
    "### üìã **Template 5: GridSearchCV**\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, None]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train['RFS_STATUS'])\n",
    "best_model = grid_search.best_estimator_\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Assessment\n",
    "\n",
    "### ‚úÖ **Self-Check Questions**\n",
    "\n",
    "1. **Classification Models**: How do different algorithms compare on your data? Why might one perform better?\n",
    "2. **C-index**: What does a C-index of 0.75 mean clinically? How is it different from accuracy?\n",
    "3. **Precision in Low-Risk**: Why is this metric important for clinical decisions about treatment de-escalation?\n",
    "4. **Cox Regression**: How do you interpret a hazard ratio of 2.0 for a gene? What about 0.5?\n",
    "5. **Risk Stratification**: Are your risk groups statistically separated? What's the p-value from log-rank test?\n",
    "6. **Model Selection**: What criteria did you use to select your final model? How did you balance different metrics?\n",
    "7. **Calibration**: Is your model well-calibrated? What would you do if it wasn't?\n",
    "\n",
    "### üèÜ **Success Criteria**\n",
    "\n",
    "You have successfully completed this notebook if you can:\n",
    "- ‚úÖ Train and compare multiple classification algorithms\n",
    "- ‚úÖ Train survival models using Cox regression\n",
    "- ‚úÖ Calculate and interpret C-index and precision metrics\n",
    "- ‚úÖ Create statistically validated risk groups\n",
    "- ‚úÖ Generate Kaplan-Meier curves showing risk separation\n",
    "- ‚úÖ Select and optimize a final model\n",
    "- ‚úÖ Validate model on test set\n",
    "- ‚úÖ Export production-ready model with documentation\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Model Development Summary\n",
    "\n",
    "### ‚úÖ **Completed Activities:**\n",
    "1. **Data Loading**: Loaded selected features from notebook 3 and preprocessed data from notebook 2\n",
    "2. **Classification Models**: Trained 7 different algorithms (Logistic, SVM, RF, GBM, NN)\n",
    "3. **Survival Models**: Trained Cox regression using RFS_MONTHS and RFS_STATUS\n",
    "4. **Clinical Metrics**: Calculated C-index and precision in low/high risk groups\n",
    "5. **Risk Stratification**: Created and validated low/medium/high risk groups with Kaplan-Meier curves\n",
    "6. **Model Optimization**: Performed hyperparameter tuning on best model\n",
    "7. **Final Validation**: Tested on held-out test set and created deployment package\n",
    "\n",
    "### üéØ **Key Achievements:**\n",
    "- **Comprehensive Modeling**: Both time-independent and time-dependent approaches\n",
    "- **Clinical Focus**: Emphasis on C-index and precision in low-risk identification\n",
    "- **Risk Groups**: Statistically validated patient stratification\n",
    "- **Production Ready**: Final model with complete documentation\n",
    "\n",
    "### üìä **Pipeline Completion:**\n",
    "‚úÖ **Notebook 1**: Data Exploration  \n",
    "‚úÖ **Notebook 2**: Data Preprocessing  \n",
    "‚úÖ **Notebook 3**: Feature Selection  \n",
    "‚úÖ **Notebook 4**: Model Development ‚Üê **YOU ARE HERE**\n",
    "\n",
    "**Congratulations on completing the entire machine learning pipeline! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
